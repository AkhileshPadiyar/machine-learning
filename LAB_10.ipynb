{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhileshPadiyar/machine-learning/blob/Lab-10/LAB_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGfeHcN2a5Mo",
        "outputId": "c95943b1-712d-4c47-fd95-535900eb45f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "XuLwXWr6bqTJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gcPQ6CNbsfQ",
        "outputId": "31913f1a-d822-43df-ea2d-a9079c217e63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text corpus\n",
        "corpus = [\n",
        "    \"I am running to catch the bus.\",\n",
        "    \"He was running fast but missed it.\",\n",
        "    \"The dogs are playing in the park.\",\n",
        "    \"She loves running and enjoys it.\",\n",
        "    \"I hate when I miss the bus.\"\n",
        "]"
      ],
      "metadata": {
        "id": "pVXjjebpb6tp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenization\n",
        "tokenized_corpus = [word_tokenize(text.lower()) for text in corpus]"
      ],
      "metadata": {
        "id": "vdw51FP6b9AA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_corpus = [[stemmer.stem(word) for word in text] for text in tokenized_corpus]"
      ],
      "metadata": {
        "id": "HYPPGW9BcIJJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_corpus = [\n",
        "    [lemmatizer.lemmatize(word, pos='v') for word in text]  # 'v' is for verbs\n",
        "    for text in tokenized_corpus\n",
        "]"
      ],
      "metadata": {
        "id": "aM7H-xiqcJmx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Implement Bag of Words using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform([' '.join(text) for text in lemmatized_corpus])"
      ],
      "metadata": {
        "id": "ThZYPymgcLPU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature names (terms in the vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "VhXrpBU4cMxx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the resulting sparse matrix to an array and display the result\n",
        "vectorized_corpus = X.toarray()"
      ],
      "metadata": {
        "id": "kw0GCWl6cOSy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llv72Mk9X58A",
        "outputId": "f168d6bb-8d6d-4876-92b6-9961741bfb34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Corpus:\n",
            "I am running to catch the bus.\n",
            "He was running fast but missed it.\n",
            "The dogs are playing in the park.\n",
            "She loves running and enjoys it.\n",
            "I hate when I miss the bus.\n",
            "\n",
            "Tokenized Corpus:\n",
            "[['i', 'am', 'running', 'to', 'catch', 'the', 'bus', '.'], ['he', 'was', 'running', 'fast', 'but', 'missed', 'it', '.'], ['the', 'dogs', 'are', 'playing', 'in', 'the', 'park', '.'], ['she', 'loves', 'running', 'and', 'enjoys', 'it', '.'], ['i', 'hate', 'when', 'i', 'miss', 'the', 'bus', '.']]\n",
            "\n",
            "Stemmed Corpus:\n",
            "[['i', 'am', 'run', 'to', 'catch', 'the', 'bu', '.'], ['he', 'wa', 'run', 'fast', 'but', 'miss', 'it', '.'], ['the', 'dog', 'are', 'play', 'in', 'the', 'park', '.'], ['she', 'love', 'run', 'and', 'enjoy', 'it', '.'], ['i', 'hate', 'when', 'i', 'miss', 'the', 'bu', '.']]\n",
            "\n",
            "Lemmatized Corpus:\n",
            "[['i', 'be', 'run', 'to', 'catch', 'the', 'bus', '.'], ['he', 'be', 'run', 'fast', 'but', 'miss', 'it', '.'], ['the', 'dog', 'be', 'play', 'in', 'the', 'park', '.'], ['she', 'love', 'run', 'and', 'enjoy', 'it', '.'], ['i', 'hate', 'when', 'i', 'miss', 'the', 'bus', '.']]\n",
            "\n",
            "Bag of Words (Vectorized Corpus):\n",
            "[[0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 2 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1]]\n",
            "\n",
            "Feature Names (Vocabulary):\n",
            "['and' 'be' 'bus' 'but' 'catch' 'dog' 'enjoy' 'fast' 'hate' 'he' 'in' 'it'\n",
            " 'love' 'miss' 'park' 'play' 'run' 'she' 'the' 'to' 'when']\n"
          ]
        }
      ],
      "source": [
        "# Display the results\n",
        "print(\"Original Corpus:\")\n",
        "for text in corpus:\n",
        "    print(text)\n",
        "\n",
        "print(\"\\nTokenized Corpus:\")\n",
        "print(tokenized_corpus)\n",
        "\n",
        "print(\"\\nStemmed Corpus:\")\n",
        "print(stemmed_corpus)\n",
        "\n",
        "print(\"\\nLemmatized Corpus:\")\n",
        "print(lemmatized_corpus)\n",
        "\n",
        "print(\"\\nBag of Words (Vectorized Corpus):\")\n",
        "print(vectorized_corpus)\n",
        "\n",
        "print(\"\\nFeature Names (Vocabulary):\")\n",
        "print(feature_names)\n"
      ]
    }
  ]
}